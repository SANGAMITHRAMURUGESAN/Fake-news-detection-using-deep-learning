# Fake News Detection Using Llama-2 7B and Deep Learning

## Project Overview
In an era rife with misinformation, the need for effective fake news detection is paramount. This project presents a sophisticated deep learning approach to discern genuine news from false narratives accurately. At the heart of this initiative is the integration of advanced transformer technology, employing the Llama-2 7B model, coupled with a combination of active and standard deep learning models.

## Problem Statement
The digital sphere's increasing misinformation complicates the accurate identification of fake news. Previous studies often face biases and limitations, stemming from reliance on singular datasets or isolated machine learning models. This project seeks to mitigate such issues by leveraging diverse datasets, thus enhancing model robustness and ensuring a more generalized analysis capability.

## Methodology
Our methodology is anchored in cutting-edge transformer technology, enhanced by active learning strategies to combat the scarcity of labeled data. The Llama-2 7B transformer model, trained on an extensive corpus, provides deep contextual insights for identifying linguistic patterns indicative of fake news. Active learning is implemented in conjunction with CNN+Bi-LSTM and DNN models to prioritize informative data points, thereby optimizing training efficiency. Traditional deep learning models like Bi-LSTM, LSTM, and a machine learning model—Logistic Regression—offer varied analytical perspectives.

## Results and Impact
The Llama-2 7B model has demonstrated an exceptional accuracy rate of 99% in fake news detection. The project underscores the significance of embedding and hyperparameter optimization in striking a balance between precision and computational efficiency. Active learning models have shown promising results with fewer data points, presenting a cost-effective labeling solution. The multifaceted approach of this project is anticipated to bolster society's defenses against misinformation, enhance the integrity of public discourse, and contribute to a more informed populace.

## Future Directions
Further developments will focus on:
- Incorporating phrases into vocabulary building for improved contextual understanding.
- Expanding the training corpus size.
- Verifying data labels with fact-checking applications.
- Refining models for real-time analysis.


